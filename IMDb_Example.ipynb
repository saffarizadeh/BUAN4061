{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDb Example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdbLMVoO+pwLntFRwYbq9L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saffarizadeh/BUAN4061/blob/main/IMDb_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"http://saffarizadeh.com/Logo.png\" width=\"300px\"/>\n",
        "\n",
        "# *BUAN 4061: Advanced Business Analytics*\n",
        "\n",
        "# **Text to Sequence: IMDb Example**\n",
        "\n",
        "Instructor: Dr. Kambiz Saffarizadeh\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Qgt7jA7IOEDH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credit: Laurence Moroney (https://github.com/lmoroney)"
      ],
      "metadata": {
        "id": "SRvWm1TqOG6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install `beautifulsoup4` to manipulate HTML. (`beautifulsoup4` is preinstalled on Colab environment.)\n",
        "\n",
        "Side Note: this library is mostly used for web scraping."
      ],
      "metadata": {
        "id": "VsIrcEkvOOGO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU8bLN2dN6d_",
        "outputId": "b2f29b09-d2c6-4574-f94a-00a5149301d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Q58N4s3gOfnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "_K6wQ6Y_PZON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the dataset"
      ],
      "metadata": {
        "id": "uor3IurbTyFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tfds.load('imdb_reviews', split=\"train\")"
      ],
      "metadata": {
        "id": "IXsULNNGPaB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is easier to first convert the dataset to an iterable of numpy arrays using `tfds.as_numpy()` before preprocessing the textual data."
      ],
      "metadata": {
        "id": "S2dA0vxTWDwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tfds.as_numpy(train_dataset)"
      ],
      "metadata": {
        "id": "cscyXijUWC1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can iterate through the dataset to see how it looks like:"
      ],
      "metadata": {
        "id": "hFaCKmbnZ4qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for item in train_dataset:\n",
        "  print(item)\n",
        "  break # breaks the loop after one iteration"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv3rg-UOaDWG",
        "outputId": "a5db1f5b-aec2-4461-8637-39c246dbc0d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 0, 'text': b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative to check what's going on inside the dataset\n",
        "train_dataset_iterator = iter(train_dataset)\n",
        "next(train_dataset_iterator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWJgBKw1aTVp",
        "outputId": "8bc17aaa-5741-4876-c824-cc837a02836f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 0,\n",
              " 'text': b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First try: extract the text without the cleaning steps"
      ],
      "metadata": {
        "id": "47HAtZIaTso-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_docs = []\n",
        "imdb_labels = []\n",
        "\n",
        "for item in train_dataset:\n",
        "    imdb_docs.append(str(item['text']))\n",
        "    imdb_labels.append(item['label'])"
      ],
      "metadata": {
        "id": "8ouKwRwAQ3lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(imdb_docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kLHOg2LRO2O",
        "outputId": "7ae608f1-9995-496d-d643-d8446194f00b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imdb_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rywm7IPfZmHj",
        "outputId": "42470044-9e0d-4a9b-9672-0b6356794f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "N7NeQEnPSHxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000)"
      ],
      "metadata": {
        "id": "QEkVkfViRSP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(imdb_docs)"
      ],
      "metadata": {
        "id": "Jxi-OGLQSKRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(imdb_docs)"
      ],
      "metadata": {
        "id": "olfFTQVNSMJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "id": "FpFmlpa0SmHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(imdb_docs[0])"
      ],
      "metadata": {
        "id": "UBlR7ZgKTSSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences[0])"
      ],
      "metadata": {
        "id": "gzVcJrEmTJKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second try: Extract the text with the clearning steps"
      ],
      "metadata": {
        "id": "az6jHn6rTeu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import string"
      ],
      "metadata": {
        "id": "mF5fY04QTRbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\",\n",
        "             \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\",\n",
        "             \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\",\n",
        "             \"he\", \"hed\", \"hes\", \"her\", \"here\", \"heres\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\",\n",
        "             \"hows\", \"i\", \"id\", \"ill\", \"im\", \"ive\", \"if\", \"in\", \"into\", \"is\", \"it\", \"its\", \"itself\",\n",
        "             \"lets\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\",\n",
        "             \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"shed\", \"shell\", \"shes\", \"should\",\n",
        "             \"so\", \"some\", \"such\", \"than\", \"that\", \"thats\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\",\n",
        "             \"there\", \"theres\", \"these\", \"they\", \"theyd\", \"theyll\", \"theyre\", \"theyve\", \"this\", \"those\", \"through\",\n",
        "             \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"wed\", \"well\", \"were\", \"weve\", \"were\",\n",
        "             \"what\", \"whats\", \"when\", \"whens\", \"where\", \"wheres\", \"which\", \"while\", \"who\", \"whos\", \"whom\", \"why\",\n",
        "             \"whys\", \"with\", \"would\", \"you\", \"youd\", \"youll\", \"youre\", \"youve\", \"your\", \"yours\", \"yourself\",\n",
        "             \"yourselves\"]"
      ],
      "metadata": {
        "id": "qdwL3uXdTg-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.python.org/3.9/library/stdtypes.html?highlight=maketrans#str.maketrans"
      ],
      "metadata": {
        "id": "WseJv3UzVN_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table = str.maketrans('', '', string.punctuation)"
      ],
      "metadata": {
        "id": "w5Qu3PzFTi_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_docs = []\n",
        "imdb_labels = []\n",
        "\n",
        "for item in train_dataset:\n",
        "    document = str(item['text'].decode('UTF-8').lower())\n",
        "    document = document.replace(\",\", \" , \")\n",
        "    document = document.replace(\".\", \" . \")\n",
        "    document = document.replace(\"-\", \" - \")\n",
        "    document = document.replace(\"/\", \" / \")\n",
        "    # Create a soup\n",
        "    soup = BeautifulSoup(document)\n",
        "    document = soup.get_text()\n",
        "\n",
        "    words = document.split()\n",
        "    filtered_document = \"\"\n",
        "    for word in words:\n",
        "        word = word.translate(table)\n",
        "        if word not in stopwords:\n",
        "            filtered_document= filtered_document + word + \" \"\n",
        "    imdb_docs.append(filtered_document)\n",
        "    imdb_labels.append(item['label'])"
      ],
      "metadata": {
        "id": "htwkdkjUTlfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(imdb_docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0q2PoORVWnT",
        "outputId": "c19605a9-9b0f-4113-b806-c53380ffde25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absolutely terrible movie  dont lured christopher walken michael ironside  great actors  must simply worst role history  even great acting not redeem movies ridiculous storyline  movie early nineties us propaganda piece  pathetic scenes columbian rebels making cases revolutions  maria conchita alonso appeared phony  pseudo  love affair walken nothing pathetic emotional plug movie devoid real meaning  disappointed movies like  ruining actors like christopher walkens good name  barely sit  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imdb_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnN5RJKPZvww",
        "outputId": "caf850ff-81f0-4699-bb19-e53b3da1eddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=25000)"
      ],
      "metadata": {
        "id": "cIxBh8xNW1Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(imdb_docs)"
      ],
      "metadata": {
        "id": "haWSf-3xW-NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(imdb_docs)"
      ],
      "metadata": {
        "id": "RYRAkCcUXArk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "id": "BWzTlyCBXDIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final dataset"
      ],
      "metadata": {
        "id": "T4Zd3zwMbQBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of documents {len(imdb_docs)}')\n",
        "print(f'Number of sequences {len(sequences)}')\n",
        "print(f'Number of labels {len(imdb_labels)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kyrOFgDbTfH",
        "outputId": "8f767a14-2ac0-460e-e927-e1546b2fca6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents 25000\n",
            "Number of sequences 25000\n",
            "Number of labels 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the tokenizer on new data"
      ],
      "metadata": {
        "id": "PUwGsts4cFkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    'Today is a sunny day',\n",
        "    'Today is a rainy day',\n",
        "    'Is it sunny today?'\n",
        "]"
      ],
      "metadata": {
        "id": "WkqM831kXEqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spNpZFC4XIoo",
        "outputId": "ca97e64e-b63a-42d7-ba93-d41abc334e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[516, 5229, 147], [516, 6489, 147], [5229, 516]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can create a reverse dictionary to translate these numbers back to the original sentence."
      ],
      "metadata": {
        "id": "DIxNL75DXjw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_word_index = {}\n",
        "\n",
        "for (key, value) in tokenizer.word_index.items():\n",
        "    reverse_word_index[value] = key\n",
        "\n",
        "# shorter version:\n",
        "# reverse_word_index = dict([(value, key) for (key, value) in tokenizer.word_index.items()])"
      ],
      "metadata": {
        "id": "Fh92_S4PXKBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_review = \"\"\n",
        "\n",
        "for i in sequences[0]:\n",
        "    word = reverse_word_index.get(i, '?')\n",
        "    decoded_review = decoded_review + ' ' + word\n",
        "\n",
        "# shorter version:\n",
        "# decoded_review = ' '.join([reverse_word_index.get(i, '?') for i in sequences[0]])"
      ],
      "metadata": {
        "id": "QV6o2HfgXsRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoded_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fsz0i3XBXwgR",
        "outputId": "452fa264-2815-4642-d453-2d1f27b7c35b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " today sunny day\n"
          ]
        }
      ]
    }
  ]
}